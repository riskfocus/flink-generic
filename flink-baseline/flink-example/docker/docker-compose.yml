#Copyright 2021-2023 Ness Digital Engineering
#
#Licensed under the Apache License, Version 2.0 (the "License");
#you may not use this file except in compliance with the License.
#You may obtain a copy of the License at
#
#http://www.apache.org/licenses/LICENSE-2.0
#
#Unless required by applicable law or agreed to in writing, software
#distributed under the License is distributed on an "AS IS" BASIS,
#WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
#See the License for the specific language governing permissions and
#limitations under the License.

version: '3.3'
# Creates all infrastructure needed
services:

    zookeeper:
        image: confluentinc/cp-zookeeper:7.2.0
        ports:
            - 2182:2182
        environment:
            HOSTNAME: localhost
            ZOOKEEPER_SERVER_ID: 2
            ZOOKEEPER_CLIENT_PORT: 2182
            ZOOKEEPER_TICK_TIME: 2000
            ZOOKEEPER_INIT_LIMIT: 5
            ZOOKEEPER_SYNC_LIMIT: 2
            ZOOKEEPER_SERVERS: localhost:2889:3889

    kafka:
        image: confluentinc/cp-enterprise-kafka:7.2.0
        container_name: kafka
        depends_on:
            - zookeeper

        environment:
            KAFKA_BROKER_ID: 10
            KAFKA_ZOOKEEPER_CONNECT: zookeeper:2182
            KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: OUTER:PLAINTEXT,INNER:PLAINTEXT
            KAFKA_ADVERTISED_LISTENERS: OUTER://localhost:19093,INNER://kafka:9093
            KAFKA_JMX_PORT: 9991
            KAFKA_INTER_BROKER_LISTENER_NAME: INNER
            KAFKA_LOG_RETENTION_MINUTES: 120 # 2 hours
            KAFKA_LOG_RETENTION_BYTES: 262144000 # 250 MB
            KAFKA_LOG_SEGMENT_BYTES: 524288000 # 500 MB
            KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
            KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
            KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
            KAFKA_AUTO_CREATE_TOPICS_ENABLE: 'false'
            KAFKA_MIN_ISYNC_REPLICAS: 1
            KAFKA_LOG4J_LOGGERS: "kafka=WARN,kafka.server=WARN,kafka.controller=WARN"
            KAFKA_LOG4J_ROOT_LOGLEVEL: "WARN"
            KAFKA_TOOLS_LOG4J_LOGLEVEL: "ERROR"
            KAFKA_TRANSACTION_STATE_LOG_NUM_PARTITIONS: 2
            KAFKA_OFFSETS_TOPIC_NUM_PARTITIONS: 2
            CONFLUENT_METRICS_REPORTER_TOPIC_REPLICAS: 1
            CONFLUENT_METRICS_ENABLE: 'false'
            KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 0
            CONFLUENT_SUPPORT_CUSTOMER_ID: 'anonymous'
            CONFLUENT_METRICS_REPORTER_PUBLISH_MS: 3000
            KAFKA_MAX_MESSAGE_BYTES: 90000000

        ports:
            - 19093:19093
            - 9093:9093

    topic-initializer:
        image: confluentinc/cp-enterprise-kafka:7.2.0
        hostname: localhost
        container_name: initializer
        depends_on:
            - kafka
        command: "bash -c -a 'echo Waiting for Kafka to be ready... && \
                       /etc/confluent/docker/configure && \
                       cub kafka-ready -b kafka:9093 1 60 && \
                       sleep 5 && \
                       kafka-topics --bootstrap-server kafka:9093 --topic input --create --replication-factor 1 --partitions 4 && \
                       kafka-topics --bootstrap-server kafka:9093 --topic output --create --replication-factor 1 --partitions 4 && \
                       kafka-topics --bootstrap-server kafka:9093 --topic telemetry --create --replication-factor 1 --partitions 4 '"
        environment:
            CONNECT_BOOTSTRAP_SERVERS: ignored
            KAFKA_ZOOKEEPER_CONNECT: ignored
            KAFKA_ADVERTISED_LISTENERS: ignored

    jmx-kafka:
        image: "sscaling/jmx-prometheus-exporter"
        ports:
            - "5556:5556"
        environment:
            CONFIG_YML: "/etc/jmx_exporter/config.yml"
        volumes:
            - ./conf/jmx_exporter/config_kafka.yml:/etc/jmx_exporter/config.yml
        container_name: jmx-kafka
        depends_on:
            - kafka

    prometheus:
        image: prom/prometheus:v2.20.1
        volumes:
            - ./conf/prometheus/prometheus.yml:/prometheus_config.yaml:ro
        command: --config.file="/prometheus_config.yaml"
        ports:
            - "9090:9090"
        restart: always

    grafana:
        image: grafana/grafana:7.1.3
        depends_on:
            - prometheus
        environment:
            GF_PATHS_DATA: /var/lib/grafana
            GF_SECURITY_ADMIN_PASSWORD: password123
        ports:
            - "3000:3000"
        volumes:
            - ./conf/grafana/provisioning:/etc/grafana/provisioning
            - ./conf/grafana/dashboards:/var/lib/grafana/dashboards
        restart: always

    jobmanager:
        image: flink:1.18.1-scala_2.12-java17
        ports:
            - "8081:8081"
        command: jobmanager
        volumes:
            - ./conf/flink-sql-scripts.sql:/flink-sql-scripts.sql
        entrypoint: >
            /bin/bash -c '
              wget -P /opt/flink/lib/ https://repo1.maven.org/maven2/org/apache/flink/flink-json/1.18.1/flink-json-1.18.1.jar; \
              wget -P /opt/flink/lib/ https://repo1.maven.org/maven2/org/apache/flink/flink-connector-kafka/3.1.0-1.18/flink-connector-kafka-3.1.0-1.18.jar; \
              wget -P /opt/flink/lib/ https://repo1.maven.org/maven2/org/apache/flink/flink-csv/1.18.1/flink-csv-1.18.1.jar; \
              wget -P /opt/flink/lib/ https://repo1.maven.org/maven2/org/apache/kafka/kafka-clients/3.4.0/kafka-clients-3.4.0.jar; \
              wget -P /opt/flink/lib/ https://github.com/knaufk/flink-faker/releases/download/v0.5.3/flink-faker-0.5.3.jar; \
              wget -P /opt/flink/lib/ https://repo1.maven.org/maven2/com/ververica/flink-sql-connector-mysql-cdc/3.0.1/flink-sql-connector-mysql-cdc-3.0.1.jar; \
              chown -R flink:flink /opt/flink/lib; \
              /docker-entrypoint.sh jobmanager
            '
        environment:
            - |
                FLINK_PROPERTIES=
                jobmanager.rpc.address: jobmanager
                metrics.reporters: prom
                metrics.reporter.prom.factory.class: org.apache.flink.metrics.prometheus.PrometheusReporterFactory
                classloader.resolve-order: parent-first
                table.exec.resource.default-parallelism: 4
                table.exec.source.idle-timeout: 200
                parallelism.default: 4        
                state.backend.type: rocksdb
                state.checkpoints.dir: file:///tmp/flink-checkpoints-directory
                state.savepoints.dir: file:///tmp/flink-savepoints-directory
                execution.checkpointing.interval: 3s

    taskmanager:
        image: flink:1.18.1-scala_2.12-java17
        depends_on:
            - jobmanager
        command: taskmanager
        entrypoint: >
            /bin/bash -c '
              wget -P /opt/flink/lib/ https://repo1.maven.org/maven2/org/apache/flink/flink-json/1.18.1/flink-json-1.18.1.jar; \
              wget -P /opt/flink/lib/ https://repo1.maven.org/maven2/org/apache/flink/flink-connector-kafka/3.1.0-1.18/flink-connector-kafka-3.1.0-1.18.jar; \
              wget -P /opt/flink/lib/ https://repo1.maven.org/maven2/org/apache/flink/flink-csv/1.18.1/flink-csv-1.18.1.jar; \
              wget -P /opt/flink/lib/ https://repo1.maven.org/maven2/org/apache/kafka/kafka-clients/3.4.0/kafka-clients-3.4.0.jar; \
              wget -P /opt/flink/lib/ https://github.com/knaufk/flink-faker/releases/download/v0.5.3/flink-faker-0.5.3.jar; \
              wget -P /opt/flink/lib/ https://repo1.maven.org/maven2/com/ververica/flink-sql-connector-mysql-cdc/3.0.1/flink-sql-connector-mysql-cdc-3.0.1.jar; \
              chown -R flink:flink /opt/flink/lib; \
              /docker-entrypoint.sh taskmanager
            '
        environment:
            - |
                FLINK_PROPERTIES=
                jobmanager.rpc.address: jobmanager
                taskmanager.numberOfTaskSlots: 4
                metrics.reporters: prom
                metrics.reporter.prom.factory.class: org.apache.flink.metrics.prometheus.PrometheusReporterFactory
                classloader.resolve-order: parent-first
                table.exec.resource.default-parallelism: 4
                table.exec.source.idle-timeout: 200
                parallelism.default: 4        
                state.backend.type: rocksdb
                state.checkpoints.dir: file:///tmp/flink-checkpoints-directory
                state.savepoints.dir: file:///tmp/flink-savepoints-directory
                execution.checkpointing.interval: 3s
